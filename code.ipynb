{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "d4f35c39",
         "metadata": {},
         "source": [
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "This is the results part of the project. In here functions are declared and described. If you want to see them applied and the results, please go to:\n",
            "\n",
            " ### __[Results](https://github.com/serbanradulescu/master_thesis/blob/main/project.ipynb)__ |  Code \n",
            "------------------------------------------------------------------------------------------------------------------------"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 63,
         "id": "cad1a2db",
         "metadata": {},
         "outputs": [],
         "source": [
            "import re\n",
            "import wget\n",
            "import requests\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "import seaborn as sns\n",
            "import geopandas as gpd\n",
            "import matplotlib.pylab as pl\n",
            "import matplotlib.pyplot as plt\n",
            "import matplotlib.gridspec as gridspec\n",
            "import matplotlib.transforms as mtransforms\n",
            "from datetime import datetime, date, timedelta\n",
            "from IPython.display import display, HTML\n",
            "from typing import List, Tuple, Optional\n",
            "from requests_html import HTMLSession\n",
            "from itertools import combinations\n",
            "from functools import lru_cache\n",
            "from zipfile import ZipFile\n",
            "from os.path import exists\n",
            "from time import sleep\n",
            "\n",
            "pd.options.mode.chained_assignment = None  # default='warn'"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 53,
         "id": "ef21cdbf",
         "metadata": {},
         "outputs": [],
         "source": [
            "@lru_cache #caching the return of the function for time optimisation; not sure if this function is supported in jupyter notebook\n",
            "def get_links(parameters:tuple[str], time:List[str] = [\"1_minute\",\"5_minutes\",\"10_minutes\",\"hourly\"]) -> dict:\n",
            "    \"\"\"Return the links from dwd corresponding to the parameters and timeframe we are interested\n",
            "\n",
            "    Args:\n",
            "        parameters (tuple[str]): a tuple with the parameters\n",
            "        time (List[str], optional): the timeframe. Defaults to [\"1_minute\",\"5_minutes\",\"10_minutes\",\"hourly\"].\n",
            "\n",
            "    Returns:\n",
            "        dict: a dictionary containing the links\n",
            "    \"\"\"\n",
            "    dwd_links = {interval:{key: None for key in parameters} for interval in time}\n",
            "    for interval in time:\n",
            "        for parameter in parameters:\n",
            "            url = 'https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/' + str(interval) + '/' + parameter + '/historical/'\n",
            "            try:\n",
            "                session = HTMLSession()\n",
            "                response = session.get(url)\n",
            "                dwd_links[interval][parameter] = response.html.absolute_links\n",
            "\n",
            "            except requests.exceptions.RequestException as e:\n",
            "                print(e)\n",
            "    return dwd_links"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "id": "761ce15f",
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_date(link:str) -> Tuple[int,int]:\n",
            "    \"\"\"Returns the years from when the data is available.\n",
            "\n",
            "    Args:\n",
            "        link (str): the link that has included the dails for the available data time\n",
            "\n",
            "    Returns:\n",
            "        Tuple[int,int]: start time, end time\n",
            "    \"\"\"\n",
            "    m = re.findall('\\d{8}', link)\n",
            "    if m:\n",
            "        return (int(m[0][:4]),int(m[1][:4]))\n",
            "    return (0,0)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "id": "f0ab715d",
         "metadata": {},
         "outputs": [],
         "source": [
            "def count_datapoints(dwd_links:dict,time,parameter:str, start_year:int, end_year:int) -> int:\n",
            "    \"\"\"Counting the datapoints for a certain parameter\n",
            "\n",
            "    Args:\n",
            "        dwd_links (dict): source of data (dwd)\n",
            "        time (_type_): time period (10_minutes, hourly)\n",
            "        parameter (str): climatic parameters we are interested in\n",
            "        start_year (int): start of the observation period\n",
            "        end_year (int): end of the observation period\n",
            "\n",
            "    Returns:\n",
            "        int: numbers of datapoints of the parameter that contain the complete period we are interested\n",
            "    \"\"\"\n",
            "    i=0\n",
            "    for link in dwd_links[time][parameter]:\n",
            "        try:\n",
            "            start_interval = int(get_date(link)[0])\n",
            "            end_interval = int(get_date(link)[1])\n",
            "            if ((start_interval <= start_year)  & (end_interval >= end_year)):\n",
            "                i = i+1\n",
            "        except:\n",
            "            pass\n",
            "    return i"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 56,
         "id": "ed5e5fdc",
         "metadata": {},
         "outputs": [],
         "source": [
            "def show_available_data(dwd_links:dict,time, parameters: List[str]):\n",
            "    data_balance = pd.DataFrame(columns = parameters, index = [str(i) + \"'s - present\" for i in range(1950,2020,10)])\n",
            "    for parameter in parameters:\n",
            "        for i in range(1950,2020,10):\n",
            "            data_balance[parameter][str(i)+ \"'s - present\"] = count_datapoints(dwd_links,time,parameter, i, 2020)\n",
            "    display(data_balance)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 57,
         "id": "62f7de1b",
         "metadata": {},
         "outputs": [],
         "source": [
            "def ids_datapoints(dwd_links:dict,time:str,parameter:str, start_year:int, end_year:int) -> List[str]:\n",
            "    \"\"\"Returns the ids of the weather station that has entries for the parameter in the mentioned timeframe\n",
            "\n",
            "    Args:\n",
            "        dwd_links (dict): source of data (dwd)\n",
            "        time (str): time period (10_minutes, hourly)\n",
            "        parameter (str): climatic parameters we are interested in\n",
            "        start_year (int): start of the observation period\n",
            "        end_year (int): end of the observation period\n",
            "\n",
            "    Returns:\n",
            "        List[str]: ids of weather stations that have the parameter that contain the complete period we are interested\n",
            "    \"\"\"\n",
            "    list = []\n",
            "    for link in dwd_links[time][parameter]:\n",
            "        try:\n",
            "            start_interval = int(get_date(link)[0])\n",
            "            end_interval = int(get_date(link)[1])\n",
            "            if ((start_interval <= start_year)  & (end_interval >= end_year)):\n",
            "                id = re.findall(\"_\\d{5}_\",str(link))[0]\n",
            "                ##print(\"link\")\n",
            "                list.append(id[1:-1])\n",
            "        except:\n",
            "            pass\n",
            "    return list\n",
            "\n",
            "parameters =(\"air_temperature\",\"dew_point\", \"moisture\", \"precipitation\")\n",
            "dwd_links = get_links(parameters)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 58,
         "id": "6901f1df",
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "def simple_common_stations(ids_parameter1: List[int],ids_parameter2: List[int]) -> List:\n",
            "    \"\"\"Common stations between two parameters\n",
            "\n",
            "    Args:\n",
            "        ids_parameter1 (List[int]): ids of the first parameter\n",
            "        ids_parameter2 (List[int]): ids of the second parameter\n",
            "\n",
            "    Returns:\n",
            "        List: a list with the common ids of the parameters\n",
            "    \"\"\"\n",
            "    list1_as_set = set(ids_parameter1)\n",
            "    intersection = list1_as_set.intersection(ids_parameter2)\n",
            "    intersection_as_list = list(intersection)\n",
            "    return intersection_as_list\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 59,
         "id": "a054ce69",
         "metadata": {},
         "outputs": [],
         "source": [
            "def create_df(parameter:str,time:str,start_year:int,end_year:int,ids:Optional[str] =None, is_test = True):\n",
            "    test_count = 0\n",
            "    if(is_test):\n",
            "        limit =4\n",
            "    else:\n",
            "        limit = 99999\n",
            "    df = pd.DataFrame()\n",
            "    for link in dwd_links[time][parameter]:   \n",
            "        if (test_count <= limit):\n",
            "            test_count+=1\n",
            "            filename = str.split(link,\"/\")[-1]\n",
            "            # Check if the file is in the time range\n",
            "            if start_year < get_date(filename)[0] or end_year > get_date(filename)[1]:\n",
            "                continue\n",
            "            #Check if the id is in the ID list\n",
            "            if ids != None:\n",
            "                id = re.findall(\"_\\d{5}_\",str(filename))[0][1:-1]\n",
            "                if id not in ids:\n",
            "                    continue\n",
            "            if(not exists(\"downloads/\" + time + \"/\" + parameter + \"/\" + filename)):\n",
            "                file_zip = wget.download(link,\"downloads/\"+time+\"/\" + parameter + \"/\")\n",
            "                print(\"downloading\" + filename + \"...\",end = \" \", flush=True)\n",
            "            else:\n",
            "                file_zip = \"downloads/\"+ time+ \"/\" + parameter + \"/\" + filename\n",
            "                #print(\"FOUND \"+ filename, end =\" \", flush=True)\n",
            "            try:    \n",
            "                with ZipFile(file_zip) as myzip:\n",
            "                    for filename in myzip.namelist():\n",
            "                        if \"Metadat\" not in filename:\n",
            "                            with myzip.open(filename) as myfile:\n",
            "                                this_df = pd.read_csv(myfile, sep =\";\")\n",
            "                                this_df[\"STATIONS_ID\"] = this_df[\"STATIONS_ID\"].apply(lambda x: str(x).zfill(5))\n",
            "                                df = pd.concat([df,this_df])\n",
            "            except:\n",
            "                print(\"Not able to open:\",filename, \"Reason: unknown.\")\n",
            "    #Checking if all given ids were found in the data\n",
            "    if ids != None:\n",
            "        if len(list(set(ids) - set(df[\"STATIONS_ID\"].unique()))) ==0:\n",
            "            print(\"All given ids accounted for\")\n",
            "        else:\n",
            "            print(\"Not found for id(s):\", list(set(ids) - set(df[\"STATIONS_ID\"].unique())) )\n",
            "    if time == \"hourly\":\n",
            "        df[\"year\"] = df[\"MESS_DATUM\"].apply(lambda x: str(x)[:4]).astype(int)\n",
            "        df[\"month\"] = df[\"MESS_DATUM\"].apply(lambda x: str(x)[4:6]).astype(int)\n",
            "        df[\"day\"] = df[\"MESS_DATUM\"].apply(lambda x: str(x)[6:8]).astype(int)\n",
            "        df[\"hour\"] = df[\"MESS_DATUM\"].apply(lambda x: str(x)[8:10]).astype(int)\n",
            "    #Cleaning the white spaces from column names\n",
            "    df.columns = [col.strip() for col in df.columns]\n",
            "    #Returning just the years requested\n",
            "    df = df[df[\"year\"] >= start_year]\n",
            "    df = df[df[\"year\"] <= end_year]\n",
            "    return df\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 60,
         "id": "89d6b2e3",
         "metadata": {},
         "outputs": [],
         "source": [
            "def coordinates_stations(ids:List[str], path_info:str ):\n",
            "    df = pd.read_csv(path_info, header=None, names=[\"raw\"], sep = \";\", encoding = \"latin1\", skiprows=2)\n",
            "    #df[\"id\"] = df[\"raw\"].apply(lambda x: x[0:5])\n",
            "    df[\"id\"] = df[\"raw\"].str.extract(r'(\\d{5})')\n",
            "    #df[\"period\"] = df[\"raw\"].str.findall(r'(\\d{8})')\n",
            "    #df[\"height\"] = df[\"raw\"].str.extract(r'(\\s+\\d{1,3}\\s+)')\n",
            "    df[\"coord\"] = df[\"raw\"].str.findall(r'(\\d{1,2}\\.{1}\\d{4})')\n",
            "    df[['lat','lon']] = pd.DataFrame(df.coord.tolist(), index= df.index)\n",
            "    df[\"lat\"]=df[\"lat\"].apply(lambda x: float(x))\n",
            "    df[\"lon\"]=df[\"lon\"].apply(lambda x: float(x))\n",
            "    processed_df = df[[\"id\",\"lat\",\"lon\"]]\n",
            "    if ids == None:\n",
            "        return processed_df\n",
            "    else:\n",
            "        return processed_df[processed_df[\"id\"].isin(ids)]"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "1a8d8763",
         "metadata": {},
         "source": [
            "Functions to help plotting:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 62,
         "id": "fa4a4f3e",
         "metadata": {},
         "outputs": [],
         "source": [
            "def select_time_range(df:pd.DataFrame,\n",
            "start_dd_mm:str, end_dd_mm:str):\n",
            "    # Step 1: create the time intervals from the input \"dd.mm\"\n",
            "    month_start = int(start_dd_mm.split(\".\")[1])\n",
            "    month_end = int(end_dd_mm.split(\".\")[1])\n",
            "    day_start = int(start_dd_mm.split(\".\")[0])\n",
            "    day_end = int(end_dd_mm.split(\".\")[0])\n",
            "    if month_start == month_end:\n",
            "        months = [month_start]\n",
            "    elif month_start < month_end:\n",
            "        months = [i for i in range(month_start,month_end +1,1)]\n",
            "    else:\n",
            "        months = [i for i in range(month_start,13,1)] + [i for i in range(1,month_end+1,1)]\n",
            "    \n",
            "    # Step 2: clean the dataframe with the created time intervals\n",
            "    df = df[df[\"month\"].isin(months)] # first the months\n",
            "    df.drop(df[(df[\"month\"]==month_start) & (df[\"day\"] < day_start)].index,inplace=True) # then take out the not included days from the first month\n",
            "    df.drop(df[(df[\"month\"]==month_end) & (df[\"day\"] > day_end)].index,inplace=True) # then those from the last month\n",
            "    return df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "6b8e33e6",
         "metadata": {},
         "outputs": [],
         "source": [
            "def plot_points_germany():\n",
            "    #Preparing the plot\n",
            "    fig, ax = plt.subplots(figsize=(12,8))\n",
            "    countries = gpd.read_file( gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
            "    countries[countries[\"name\"] == \"Germany\"].plot(color=\"lightgrey\",ax=ax)\n",
            "    #Plotting for each time range\n",
            "    for start_year in range(1970,1949,-10):\n",
            "        moisture_year_h = ids_datapoints(dwd_links,\"hourly\",\"moisture\",start_year,2020)\n",
            "        dew_point_year_h = ids_datapoints(dwd_links,\"hourly\",\"dew_point\",start_year,2020)\n",
            "        air_temp_year_h = ids_datapoints(dwd_links,\"hourly\",\"air_temperature\",start_year,2020)\n",
            "\n",
            "        common_ids = (simple_common_stations(simple_common_stations(moisture_year_h,dew_point_year_h),air_temp_year_h))\n",
            "        stations_coordinates = coordinates_stations(common_ids,\"downloads/hourly/dew_point/TD_Stundenwerte_Beschreibung_Stationen.txt\")\n",
            "\n",
            "\n",
            "        \n",
            "        sns.scatterplot(x=\"lon\", y=\"lat\",data=stations_coordinates, label = f\"{start_year}- 2020\")#,title=f\"Weather stations that measure the parameters required for applying \\n the disease models in the time period of {start_year} - present\",  ax=ax)\n",
            "    \n",
            "    plt.legend(title = \"Available data\")\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "cec3ffed",
         "metadata": {},
         "source": [
            "### Plots"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "8fa084d5",
         "metadata": {},
         "outputs": [],
         "source": [
            "def plot_optimal_temperature(\n",
            "    df:pd.DataFrame, \n",
            "    temp_min:float, temp_max:float, \n",
            "    hist_start:float,hist_end:float,\n",
            "    start_dd_mm:str,end_dd_mm:str,\n",
            "    moving_average: int):\n",
            "    \"\"\"Creates the plot for the optimal temperature\n",
            "\n",
            "    Args:\n",
            "        df (pd.DataFrame): the dataframe with hourly temperature\n",
            "        temp_min (float): minimum of temperature interval\n",
            "        temp_max (float): maximum of temperature interval\n",
            "        hist_start (float): start of the reference period\n",
            "        hist_end (float): end of the reference period\n",
            "        start_dd_mm (str): start date in the dd.mm format\n",
            "        end_dd_mm (str): end date in the dd.mm format\n",
            "        moving_average (int): the number of years for the moving average (e.g.7)\n",
            "    \"\"\"\n",
            "    \n",
            "    # Step 1: create the time intervals from the input \"dd.mm\"\n",
            "    df = select_time_range(df,start_dd_mm=start_dd_mm, end_dd_mm=end_dd_mm)\n",
            "    # Step 2: apply the function\n",
            "    df[\"useful_t\"] = df.TT_TU.apply(lambda x: 1 if (x >= temp_min and x <= temp_max) else 0)\n",
            "    \n",
            "    # Step 3: process and prepare for plotting\n",
            "    df= df.groupby([\"year\"]).mean()\n",
            "    avg_hist= df[(df.index <= hist_end)&(df.index >= hist_start)][\"useful_t\"].mean()\n",
            "    max_hist = df[(df.index <= hist_end)&(df.index >= hist_start)][\"useful_t\"].max()\n",
            "    min_hist = df[(df.index <= hist_end)&(df.index >= hist_start)][\"useful_t\"].min()\n",
            "    df[f'{moving_average}years_average'] = df.useful_t.rolling(moving_average).mean()\n",
            "\n",
            "    # Step 4: plot\n",
            "    plt.figure(figsize = (15,8))\n",
            "    sns.lineplot(x = 'year', y = 'useful_t',data = df, label=\"yearly optimal hours %\", alpha = 0.55)\n",
            "    sns.lineplot(x = 'year', y = f'{moving_average}years_average',data = df, label=f'{moving_average} years average', color = \"orange\")\n",
            "    sns.lineplot(x = df.index, y = min_hist,linestyle=\"dashed\", label=f\"minimum in the historical period ({hist_start}-{hist_end})\")\n",
            "    sns.lineplot(x = df.index, y = avg_hist,linestyle=\"dashed\", label=f\"average in the historical period ({hist_start}-{hist_end})\")\n",
            "    sns.lineplot(x = df.index, y = max_hist, linestyle=\"dashed\", label=f\"maximum period in the historical period ({hist_start}-{hist_end})\")\n",
            "    plt.ylabel(\"% of hours with optimal temperature\")\n",
            "    #plt.plot([hist_end,hist_end], [-0.00,0.05], lw=2, color = \"0.65\", label = \"historical period (left)\")\n",
            "\n",
            "    plt.figtext(0.15, 0.021, f\"Figure 1. Variation of optimal temperature % for Septoria tritici in Germany from 1950 - 2020 compared to the reference period of ({hist_start} - {hist_end}). Optimal temperature is considered when air \\n temperature is between {temp_min} and {temp_max} degrees Celsius. The yearly time range is between sowing of wheat and harvesting in Germany, which is considered: {start_dd_mm} - {end_dd_mm}, corresponding to the interval when 90% of the crop was is in that stage \" )\n",
            "    plt.show()\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f916d7ea",
         "metadata": {},
         "outputs": [],
         "source": [
            "def plot_lw_RHt(df:pd.DataFrame, \n",
            "                thresholds:list[float],\n",
            "                hist_start:float,hist_end:float,\n",
            "                start_dd_mm:str,end_dd_mm:str,\n",
            "                moving_average: int,\n",
            "                hours:list[int]):\n",
            "\n",
            "    # Step 1: create the time intervals from the input \"dd.mm\"\n",
            "    df = select_time_range(df,start_dd_mm=start_dd_mm, end_dd_mm=end_dd_mm)\n",
            "    # Step 2: apply the function\n",
            "    for i in thresholds:\n",
            "        df[f\"lw{i}\"]=df[\"RF_STD\"].apply(lambda x: 1 if float(x) >= i else 0)\n",
            "    \n",
            "    # Step 3: process and prepare for plotting\n",
            "    df= df.groupby(\"year\").mean()\n",
            "    for i in thresholds:\n",
            "        df[f'lw{i}_7years_average'] = df[f\"lw{i}\"].rolling(moving_average).mean()\n",
            "        df[f\"avg_hist_lw{i}\"]= df[(df.index >= hist_start)&(df.index <= hist_end)][f\"lw{i}\"].mean()\n",
            "    \n",
            "    # Step 4: plot\n",
            "    plt.figure(figsize = (15,7.5))\n",
            "    for i in thresholds:\n",
            "        sns.lineplot( x=\"year\", y = f\"lw{i}\", data= df, label= f\"leaf humidity treshold set at RH = {i}\",alpha=0.33)\n",
            "        sns.lineplot(x = 'year', y = f'lw{i}_7years_average',data = df, label=f'lw{i}_7years_average')\n",
            "        sns.lineplot(x = \"year\", y = f\"avg_hist_lw{i}\",data = df,linestyle=\"dashed\", label=f\"{moving_average} years moving average for lw{i}\")\n",
            "    plt.title(f\"Leaf wetness for different RH treshold measured in the interval {hours}\")\n",
            "    plt.figtext(0.15, 0.031, f\"Fig 4. Leaf wetness events from RH leaf wetness model applied for different RH tresholds on data from 1950 - 2019  in Germany.\" )\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b744cf46",
         "metadata": {},
         "outputs": [],
         "source": [
            "def plot_lw_dpd(df,start_dd_mm:str,end_dd_mm:str,):\n",
            "    \n",
            "    # Step 1: create the time intervals from the input \"dd.mm\"\n",
            "    df = select_time_range(df,start_dd_mm=start_dd_mm, end_dd_mm=end_dd_mm)\n",
            "\n",
            "    # Step 2: apply the function\n",
            "    df[\"difference\"]=df.apply(lambda x: (x['TT']- x['TD']), axis=1)\n",
            "\n",
            "    # Step 3: process and prepare for plotting\n",
            "    df = df.groupby(\"year\").mean()\n",
            "    avg50_79= df[df.index <= 1979][\"difference\"].mean()\n",
            "    max50_79 = df[df.index <= 1979][\"difference\"].max()\n",
            "    min50_79 = df[df.index <= 1979][\"difference\"].min()\n",
            "    df['7yrs_average'] = df.difference.rolling(7).mean()\n",
            "\n",
            "    # Step 4: plot\n",
            "    plt.figure(figsize = (15,8))\n",
            "    sns.lineplot(x=df.index, y= df[\"difference\"])#, label = \"average yearly difference\")\n",
            "    sns.lineplot(x = df.index, y = df['7yrs_average'], label=\"7 years average\", color = \"orange\")\n",
            "    sns.lineplot(x = df.index, y = min50_79,linestyle=\"dashed\", label=\"minimum in the historical period (1950-1979)\")\n",
            "    sns.lineplot(x = df.index, y = avg50_79,linestyle=\"dashed\", label=\"average in the historical period (1950-1979)\")\n",
            "    sns.lineplot(x = df.index, y = max50_79, linestyle=\"dashed\", label=\"maximum perios in the historical period (1950-1979)\")\n",
            "\n",
            "\n",
            "    plt.figtext(0.15, 0.021, \"Figure 3. Variation of leaf wetness determined trough dew point difference % for Septoria tritici in Germany in the time period of 1950 - 2020. Optimal temperature is considered when air \\n temperature is between 15 and 25 degrees Celsius in the months of Decemvber to April. \" )\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f5a4de74",
         "metadata": {},
         "outputs": [],
         "source": [
            "def plot_dryness(df,start_dd_mm:str,end_dd_mm:str,treshhold:float =70):\n",
            "\n",
            "    # Step 1: create the time intervals from the input \"dd.mm\"\n",
            "    df = select_time_range(df,start_dd_mm=start_dd_mm, end_dd_mm=end_dd_mm)\n",
            "    \n",
            "    # Step 2: apply the function\n",
            "    df[f\"dry_leaf\"]=df[\"RF_STD\"].apply(lambda x: 1 if float(x) <= treshhold else 0)\n",
            "\n",
            "    # Step 3: process and prepare for plotting\n",
            "    df= df.groupby(\"year\").mean()\n",
            "    df['7yrs_average'] = df.dry_leaf.rolling(7).mean()\n",
            "    avg50_79= df[df.index <= 1979][\"dry_leaf\"].mean()\n",
            "\n",
            "    # Step 3: plot\n",
            "    plt.figure(figsize = (15,7))\n",
            "    sns.lineplot( x=df.index, y = avg50_79 , label = \"historical (1950-1979) average dry leaf\")\n",
            "    sns.lineplot( x=\"year\", y = \"dry_leaf\", data= df, label = \"yearly dry leaf\")\n",
            "    sns.lineplot( x=\"year\", y = '7yrs_average', data= df, label = \"7 years average dry leaf\")\n",
            "    plt.title(f\"Leaf dryness for RH = {treshhold} threshhold\")\n",
            "    plt.ylabel(\"% of hours with leaf dryness\")\n",
            "    plt.figtext(0.15, 0.031, f\"Fig 5. Leaf dryness events from RH leaf wetness model applied for treshold {treshhold} on data from 1950 - 2019  in Germany.\" )\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 64,
         "id": "0e4ab17a",
         "metadata": {},
         "outputs": [],
         "source": [
            "def equation_fusarium(t:float):\n",
            "    tmin = 5\n",
            "    tmax = 30\n",
            "    if(t<=tmin):\n",
            "        return 0\n",
            "    if(t >= tmax):\n",
            "        return 0\n",
            "    b,c= 17.2, 10.5\n",
            "    teq = (t-tmin)/(tmax-tmin)\n",
            "    y = (teq**b) * ((1-teq)**c)\n",
            "    return y * 98294267.23029275 / 1.0218637974743057\n",
            "\n",
            "#𝑌=𝑐**(100−RH)/(1+𝑒 ** (𝑎−𝑏×𝑡))\n",
            "\n",
            "def equation_fusarium_rh(rh:float) -> float:\n",
            "    #a = 1\n",
            "    #b = 2\n",
            "    if (rh > 100):\n",
            "        rh = 100\n",
            "    c = 0.850\n",
            "    y = c ** (100-rh) \n",
            "    return y * 1/0.85\n",
            "\n",
            "\n",
            "def plot_equation_temperature(\n",
            "    df_airtemp:pd.DataFrame, df_moisture,\n",
            "    temp_min:float, temp_max:float, \n",
            "    hist_start:float,hist_end:float,\n",
            "    start_dd_mm:str,end_dd_mm:str,\n",
            "    moving_average: int):\n",
            "\n",
            "    # Step 1: create the time intervals from the input \"dd.mm\"\n",
            "    df_airtemp = select_time_range(df_airtemp,start_dd_mm=start_dd_mm, end_dd_mm=end_dd_mm)\n",
            "    df_moisture = select_time_range(df_moisture,start_dd_mm=start_dd_mm, end_dd_mm=end_dd_mm)\n",
            "    # Step 2: apply the function for the model\n",
            "\n",
            "    # Step 2.1: the model for temperature\n",
            "    df_airtemp[\"useful_t\"] = df_airtemp.TT_TU.apply(equation_fusarium)\n",
            "    \n",
            "    # Step 2.2: the model for moisutre\n",
            "    df_moisture[\"rh_risk\"] = df_moisture.RF_STD.apply(equation_fusarium_rh)\n",
            "\n",
            "    # Step 3: process and prepare for plotting\n",
            "    # Step 3.1: for temperature\n",
            "    df_airtemp= df_airtemp.groupby([\"year\"]).mean()\n",
            "    avg_hist= df_airtemp[(df_airtemp.index <= hist_end)&(df_airtemp.index >= hist_start)][\"useful_t\"].mean()\n",
            "    max_hist = df_airtemp[(df_airtemp.index <= hist_end)&(df_airtemp.index >= hist_start)][\"useful_t\"].max()\n",
            "    min_hist = df_airtemp[(df_airtemp.index <= hist_end)&(df_airtemp.index >= hist_start)][\"useful_t\"].min()\n",
            "    df_airtemp[f'{moving_average}years_average'] = df_airtemp.useful_t.rolling(7).mean()\n",
            "\n",
            "    # Step 3.2: for moisture\n",
            "    df_moisture= df_moisture.groupby([\"year\"]).mean()\n",
            "    avg_hist_m= df_moisture[(df_moisture.index <= hist_end)&(df_moisture.index >= hist_start)][\"rh_risk\"].mean()\n",
            "    #max_hist = df_airtemp[(df_airtemp.index <= hist_end)&(df_airtemp.index >= hist_start)][\"useful_t\"].max()\n",
            "    #min_hist = df_airtemp[(df_airtemp.index <= hist_end)&(df_airtemp.index >= hist_start)][\"useful_t\"].min()\n",
            "    df_moisture[f'{moving_average}years_average'] = df_moisture.rh_risk.rolling(7).mean()\n",
            "\n",
            "    # Step 4: plot\n",
            "    # Step 4.1: Make a grid\n",
            "    gs = gridspec.GridSpec(10, 10)\n",
            "    fig = plt.figure(figsize = (15,8))\n",
            "\n",
            "    #Step 4.2: Plot in different spaces of the grid\n",
            "    #Step 4.2.1: Left upper corner\n",
            "    ax1 = fig.add_subplot(gs[0:2, 0:5]) \n",
            "    degr =[equation_fusarium(i/100) for i in range(500,3000,1)]\n",
            "    sns.lineplot(x=[i/100 for i in range(500,3000,1)], y = degr, ax=ax1)\n",
            "    ax1.set_xlabel(\"Temperature ($^\\circ$C)\")\n",
            "    ax1.set_ylabel(\"Development of Fusarium\")\n",
            "\n",
            "    #Step 4.2.2: Right upper corner\n",
            "    ax2 = fig.add_subplot(gs[0:2, 5:10], sharey=ax1) \n",
            "    degr =[equation_fusarium_rh(i) for i in range(65,101)]\n",
            "    sns.lineplot(x=[i for i in range(65,101)], y = degr, ax=ax2)\n",
            "    ax2.set_xlabel(\"RH (%)\")\n",
            "    plt.setp(ax2.get_yticklabels(), visible=False)\n",
            "\n",
            "    #Step 4.2.3: Middle center\n",
            "    ax3 = fig.add_subplot(gs[3:7, :]) \n",
            "    sns.lineplot(x = 'year', y = 'useful_t',data = df_airtemp, label=\"yearly temperature risk\", ax=ax3, alpha = 0.55)\n",
            "    sns.lineplot(x = 'year', y = f'{moving_average}years_average',ax=ax3,data = df_airtemp, label=f'{moving_average} years average')\n",
            "    #sns.lineplot(x = df_airtemp.index, y = min_hist,linestyle=\"dashed\",ax=ax3, label=f\"minimum in the historical period ({hist_start}-{hist_end})\")\n",
            "    sns.lineplot(x = df_airtemp.index, y = avg_hist,linestyle=\"dashed\", ax=ax3,label=f\"historic temperature risk ({hist_start}-{hist_end})\")\n",
            "    #sns.lineplot(x = df_airtemp.index, y = max_hist, linestyle=\"dashed\",ax=ax3, label=f\"maximum period in the historical period ({hist_start}-{hist_end})\")\n",
            "    #plt.ylabel(\"% of hours with optimal temperature\")\n",
            "    #plt.plot([hist_end,hist_end], [-0.00,0.05], lw=2, color = \"0.65\", label = \"historical period (left)\")\n",
            "    ax3.set_xlabel(\"\")\n",
            "    ax3.set_ylabel(\"risk from temperature\")\n",
            "\n",
            "    #Step 4.2.4: Bottom center\n",
            "    ax4 = fig.add_subplot(gs[7:11, :],sharex = ax3) # row 1, span all columns\n",
            "    ax4.sharex(ax3)\n",
            "    sns.lineplot(x = 'year', y = 'rh_risk',data = df_moisture, label=\"yearly rh risk\", ax=ax4, alpha = 0.55)\n",
            "    sns.lineplot(x = 'year', y = f'{moving_average}years_average',ax=ax4,data = df_moisture, label=f'{moving_average} years average')\n",
            "    sns.lineplot(x = df_moisture.index, y = avg_hist_m,linestyle=\"dashed\", ax=ax4,label=f\"historic rh risk ({hist_start}-{hist_end})\")\n",
            "    ax4.set_ylabel(\"risk from RH\")\n",
            "\n",
            "    plt.setp(ax3.get_xticklabels(), visible=False)\n",
            "\n",
            "    #Step 4.3: Add suptitles, labels, ticks\n",
            "    fig.suptitle(\"Evolution of parameters associated with disease development of \\n Fusarium graminearum in Maize\", fontsize=16)\n",
            "    for ax, label in zip([ax1,ax2,ax3,ax4],[\"a\",\"b\",\"c\",\"d\"]):\n",
            "        trans = mtransforms.ScaledTranslation(10/72, -5/72, fig.dpi_scale_trans)\n",
            "        #ax.text(0,1 ,label,transform=ax.transAxes + trans,fontsize='medium', verticalalignment='top', fontfamily='serif',bbox=dict(facecolor='0.7', edgecolor='none', pad=3.0))\n",
            "\n",
            "    #plt.figtext(0.1, 0.00, \"Figure 4. Evolution of environmental factors asociated with development of Perithecia in $\\it{Fusarium }$  $\\it{graminearum}$ in the time period of 1950 - 2020 in 20 weather stations in Germany. \\n (a)(b) $\\it{Fusarium }$  $\\it{graminearum}$ development at different temperatures and RH, where 1 on y axis correspods to the optimal temperature / humidity. \\n (c)(d) Evolution of the disease risk corresponding to the given parameter, calculated yearly as a mean of hourly risk, on the months of June August.\" )\n",
            "    plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "192cc1b4",
         "metadata": {},
         "outputs": [],
         "source": [
            "def create_csv_for_app(time, parameter, start_year, end_year, ids):\n",
            "    for link in dwd_links[time][parameter]:   \n",
            "            filename = str.split(link,\"/\")[-1]\n",
            "            # Check if the file is in the time range\n",
            "            if start_year < get_date(filename)[0] or end_year > get_date(filename)[1]:\n",
            "                continue\n",
            "            #Check if the id is in the ID list\n",
            "            if ids != None:\n",
            "                id = re.findall(\"_\\d{5}_\",str(filename))[0][1:-1]\n",
            "                if id not in ids:\n",
            "                    continue\n",
            "            else:\n",
            "                id = \"unknown\"\n",
            "            if(not exists(\"downloads/\" + time + \"/\" + parameter + \"/\" + filename)):\n",
            "                file_zip = wget.download(link,\"downloads/\"+time+\"/\" + parameter + \"/\")\n",
            "                print(\"downloading\" + filename + \"...\",end = \" \", flush=True)\n",
            "            else:\n",
            "                file_zip = \"downloads/\"+ time+ \"/\" + parameter + \"/\" + filename\n",
            "                #print(\"FOUND \"+ filename, end =\" \", flush=True)\n",
            "            try:    \n",
            "                with ZipFile(file_zip) as myzip:\n",
            "                    for filename in myzip.namelist():\n",
            "                        if \"Metadat\" not in filename:\n",
            "                            with myzip.open(filename) as myfile:\n",
            "                                \n",
            "                                df = pd.read_csv(myfile, sep =\";\")\n",
            "                                df[\"STATIONS_ID\"] = df[\"STATIONS_ID\"].apply(lambda x: str(x).zfill(5))\n",
            "                                df.columns = [col.strip() for col in df.columns]\n",
            "                                df[\"year\"] = df[\"MESS_DATUM\"].apply(lambda x: str(x)[:4]).astype(int)\n",
            "                                df[\"month\"] = df[\"MESS_DATUM\"].apply(lambda x: str(x)[4:6]).astype(int)\n",
            "                                df[\"day\"] = df[\"MESS_DATUM\"].apply(lambda x: str(x)[6:8]).astype(int)\n",
            "                                df[\"hour\"] = df[\"MESS_DATUM\"].apply(lambda x: str(x)[8:10]).astype(int)\n",
            "                                df = df[[\"STATIONS_ID\",\"MESS_DATUM\",\"TT_TU\",\"year\",\"month\",\"day\",\"hour\"]]\n",
            "                                df.replace(-999.0, np.nan, inplace=True)\n",
            "                                df.to_csv(f\"app/data/{time}/{parameter}/{start_year}/{id}.csv\")\n",
            "            except:\n",
            "                print(\"Not able to open:\",filename, \"Reason: unknown.\")\n",
            "#ids_to_export = ['02601', '05705', '05792', '00691', '01975', '02290', '05906', '04104', '04371', '03032', '00867', '01639', '02597', '04887', '05371', '00701', '01691', '00656', '01550', '03730', '03631', '02014', '05100', '02261']\n",
            "#create_csv_for_app(\"hourly\", \"air_temperature\", 1950, 2020, ids_to_export)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "900271b1",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'28.08'"
                  ]
               },
               "execution_count": 16,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "def quantile_date_stage_crop(crop:str, quantile:float, stage:int ):\n",
            "    if crop not in [\"mais\",\"wheat\"]:\n",
            "        raise ValueError(\"Crop not found\")\n",
            "    bbch = pd.read_csv(\"downloads/bbch/bbch_\" + crop + \".csv\", encoding=\"latin1\")\n",
            "    stage_date = bbch[bbch[\"Phase_id\"]== stage]\n",
            "    arr = stage_date.Jultag.to_numpy()\n",
            "    day_num = str(int(np.quantile(arr, quantile)))\n",
            "    # adjusting day num\n",
            "    day_num.rjust(3 + len(day_num), '0')\n",
            "  \n",
            "    # Initialize year\n",
            "    year = \"1950\"\n",
            "  \n",
            "    # Initializing start date\n",
            "    strt_date = date(int(year), 1, 1)\n",
            "  \n",
            "    # converting to date\n",
            "    res_date = strt_date + timedelta(days=int(day_num) - 1)\n",
            "    res = res_date.strftime(\"%d.%m\")\n",
            "    return res"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f39be9e0",
         "metadata": {},
         "outputs": [],
         "source": [
            "def plot_harvest_date_mais():\n",
            "    bbch_mais = pd.read_csv(\"downloads/bbch/bbch_mais.csv\", encoding = \"latin1\")\n",
            "    harvest_date = bbch_mais[(bbch_mais[\"Phase_id\"] == 24)]\n",
            "    plt.figure(figsize = (15,7))\n",
            "    sns.boxenplot(x=harvest_date.Referenzjahr, y=harvest_date.Jultag)\n",
            "    plt.title(f\"Harvesting day in Germany\")\n",
            "    arr = harvest_date.Jultag.to_numpy()\n",
            "    print(\"Q1 quantile of arr : \", np.quantile(arr, .25))\n",
            "    print(\"Q2 quantile of arr : \", np.quantile(arr, .50))\n",
            "    print(\"Q3 quantile of arr : \", np.quantile(arr, .75))\n",
            "    print(\"90% of corn is harvested at : \", np.quantile(arr, .90))\n",
            "    print(\"95% of corn is harvested at : \", np.quantile(arr, .95))\n",
            "    print(\"99% of corn is harvested at : \", np.quantile(arr, .99))\n",
            "\n",
            "\n",
            "    \n",
            "def plot_stage_date_wheat(stage:int):\n",
            "    # 10 = seeding\n",
            "    # 12 = bbch10\n",
            "    # 15 = bbch31\n",
            "    # 18 = bbch51\n",
            "    # 19 = bbch75\n",
            "    # 23 = begin harvesting\n",
            "    # 24 = harvested\n",
            "    bbch_mais = pd.read_csv(\"downloads/bbch/bbch_wheat.csv\", encoding = \"latin1\")\n",
            "    harvest_date = bbch_mais[(bbch_mais[\"Phase_id\"] == stage)]\n",
            "    plt.figure(figsize = (15,7))\n",
            "    sns.boxenplot(x=harvest_date.Referenzjahr, y=harvest_date.Jultag)\n",
            "    plt.title(f\"Harvesting day in Germany\")\n",
            "    arr = harvest_date.Jultag.to_numpy()\n",
            "    print(\"Q1 quantile of arr : \", np.quantile(arr, .25))\n",
            "    print(\"Q2 quantile of arr : \", np.quantile(arr, .50))\n",
            "    print(\"Q3 quantile of arr : \", np.quantile(arr, .75))\n",
            "    print(\"90% of wheat reaches bbch51 at : \", np.quantile(arr, .90))\n",
            "    print(\"95% of wheat reaches bbch51 at : \", np.quantile(arr, .95))\n",
            "    print(\"99% of wheat reaches bbch51 at : \", np.quantile(arr, .99))\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "e0c09579",
         "metadata": {},
         "source": [
            "### The following code is written just to email me when the files are downloaded/models are trained"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "f6321219",
         "metadata": {},
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "80618e87",
         "metadata": {},
         "outputs": [],
         "source": [
            "import smtplib, ssl, os\n",
            "\n",
            "def mail_me():\n",
            "    port = 465  # For SSL\n",
            "    smtp_server = \"smtp.gmail.com\"\n",
            "    sender_email = \"computersays521@gmail.com\"  # Enter your address\n",
            "    receiver_email = \"radulescu_serban_petre@yahoo.com\"  # Enter receiver address\n",
            "    password = open(\"mailingfile.txt\",\"r\").readlines()[0]\n",
            "    message = \"\"\"\\\n",
            "    Subject: Hi there\n",
            "\n",
            "    It seems that what you were working on is done. Or you had some errors. Either way the program is completed. \"\"\"\n",
            "\n",
            "    context = ssl.create_default_context()\n",
            "    with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:\n",
            "        server.login(sender_email, password)\n",
            "        server.sendmail(sender_email, receiver_email, message)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fec4c299",
         "metadata": {},
         "outputs": [],
         "source": [
            "def get_phase_definition():\n",
            "    df = pd.read_csv(\"https://opendata.dwd.de/climate_environment/CDC/observations_germany/phenology/annual_reporters/crops/recent/PH_Beschreibung_Phasendefinition_Jahresmelder_Landwirtschaft_Kulturpflanze.txt\", sep=\";\", encoding =\"latin1\")\n",
            "    return df\n",
            "def get_bbch(path):\n",
            "    # mais : https://opendata.dwd.de/climate_environment/CDC/observations_germany/phenology/annual_reporters/crops/historical/PH_Jahresmelder_Landwirtschaft_Kulturpflanze_Mais_1936_2020_hist.txt\n",
            "    # wheat : https://opendata.dwd.de/climate_environment/CDC/observations_germany/phenology/annual_reporters/crops/historical/PH_Jahresmelder_Landwirtschaft_Kulturpflanze_Winterweizen_1925_2020_hist.txt\n",
            "    df = pd.read_csv(path, sep =\";\")\n",
            "    #df.columns = [col.strip() for col in df.columns]\n",
            "    return df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d497ded3",
         "metadata": {},
         "outputs": [],
         "source": [
            "\"\"\"\n",
            "bbch = get_bbch(\"https://opendata.dwd.de/climate_environment/CDC/observations_germany/phenology/annual_reporters/crops/historical/PH_Jahresmelder_Landwirtschaft_Kulturpflanze_Mais_1936_2020_hist.txt\")\n",
            "bbch.columns = [col.strip() for col in bbch.columns]\n",
            "bbch[\"Stations_id\"] = bbch[\"Stations_id\"].apply(lambda x: str(x).zfill(5))\n",
            "#bbch = bbch[bbch[\"Stations_id\"].isin(common_ids)]\n",
            "for id in bbch[\"Stations_id\"].unique():\n",
            "    print(id)\n",
            "bbch.to_csv(\"bbch_mais.csv\")\n",
            "\"\"\""
         ]
      }
   ],
   "metadata": {
      "hide_input": false,
      "interpreter": {
         "hash": "8488b1165f104a905cf6677a9ffc3532c3736b5873a3271a01fb03afba4b3bc1"
      },
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.12"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
